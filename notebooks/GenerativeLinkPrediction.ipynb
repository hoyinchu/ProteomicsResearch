{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import nan\n",
    "import pandas as pd\n",
    "import json\n",
    "from csv import writer\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "PATH_ROOT = os.getcwd().replace(\"\\\\\",\"/\").replace(\"/notebooks\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original vector values are both nonzero\n",
    "def find_common_observations(vector1,vector2):\n",
    "  vector1_bool = np.where(vector1 != 0, 1, 0)\n",
    "  vector2_bool = np.where(vector2 != 0, 1, 0)\n",
    "  take_indices = np.logical_and(vector1_bool,vector2_bool)\n",
    "  take_indices = take_indices.nonzero()[0]\n",
    "  x1 = np.take(vector1,take_indices)\n",
    "  x2 = np.take(vector2,take_indices)\n",
    "  return x1,x2\n",
    "\n",
    "# Appends list of tuples to csv\n",
    "def append_to_csv(file_name,column_names,cor_tuples):\n",
    "  with open(file_name, 'a+', newline='') as write_obj:\n",
    "    csv_writer = writer(write_obj)\n",
    "    if column_names is not None:\n",
    "      csv_writer.writerow(column_names)\n",
    "    for cor_tuple in cor_tuples:\n",
    "      csv_writer.writerow(cor_tuple)\n",
    "\n",
    "def write_json_to(json_dict,path):\n",
    "  json_to_write = json.dumps(json_dict)\n",
    "  write_file = open(path,\"w\")\n",
    "  write_file.write(json_to_write)\n",
    "  write_file.close()\n",
    "\n",
    "def read_json_from(path):\n",
    "  with open(path, \"r\") as read_file:\n",
    "    init_dict = json.load(read_file)\n",
    "    if isinstance(init_dict,str):\n",
    "        return eval(init_dict)\n",
    "    return init_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomeHD_path = f\"{PATH_ROOT}/data_sources/ProteomeHD/ProteomeHD_v1_1.csv\"\n",
    "proteomeHD_df = pd.read_csv(proteomeHD_path)\n",
    "proteomeHD_simplified_protein_ids = proteomeHD_df[\"Simplified_protein_ID\"].to_numpy()\n",
    "proteomeHD_majority_protein_ids = proteomeHD_df[\"Majority_protein_IDs\"].to_numpy()\n",
    "proteomeHD_feature_matrix = proteomeHD_df.iloc[:,4:].fillna(0).to_numpy()\n",
    "proteomeHD_feature_matrix_with_na = proteomeHD_df.iloc[:,4:].to_numpy()\n",
    "major_simplified_idx_lookup_path = f\"{PATH_ROOT}/data_sources/ProteomeHD/major_simplified_to_idx_lookup.json\"\n",
    "major_simplified_idx_lookup = read_json_from(major_simplified_idx_lookup_path)\n",
    "\n",
    "pQTL_protein_path = f\"{PATH_ROOT}/data_sources/pQTL/pQTL_protein_converted.csv\"\n",
    "pQTL_protein_df = pd.read_csv(pQTL_protein_path)\n",
    "pQTL_protein_ids = pQTL_protein_df['uniprotswissprot'].to_numpy()\n",
    "pQTL_protein_feature_matrix = pQTL_protein_df.iloc[:,2:].fillna(0).to_numpy()\n",
    "pQTL_protein_idx_lookup_path = f\"{PATH_ROOT}/data_sources/pQTL/pQTL_protein_converted_idx_lookup.json\"\n",
    "pQTL_protein_idx_lookup = read_json_from(pQTL_protein_idx_lookup_path)\n",
    "\n",
    "nikolai_protein_path = f\"{PATH_ROOT}/data_sources/Nikolai/Proteins-processed.csv\"\n",
    "nikolai_protein_df = pd.read_csv(nikolai_protein_path)\n",
    "nikolai_protein_ids = nikolai_protein_df['uniprot_id']\n",
    "nikolai_protein_feature_matrix = nikolai_protein_df.iloc[:,1:].fillna(0).to_numpy()\n",
    "nikolai_protein_idx_lookup_path = f\"{PATH_ROOT}/data_sources/Nikolai/protein_processed_lookup.json\"\n",
    "nikolai_protein_idx_lookup = read_json_from(nikolai_protein_idx_lookup_path)\n",
    "\n",
    "coexpression_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_coexpression_relation_lookup.json\"\n",
    "cooccurence_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_cooccurence_relation_lookup.json\"\n",
    "experiments_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_experiments_relation_lookup.json\"\n",
    "fusion_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_fusion_relation_lookup.json\"\n",
    "homology_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_homology_relation_lookup.json\"\n",
    "cocomplex_lookup_path = f\"{PATH_ROOT}/data_sources/Corum/all_corum_complex_pairs_size_only.json\"\n",
    "database_lookup_path = f\"{PATH_ROOT}/data_sources/StringDB/human/medium_confidence_database_relation_lookup.json\"\n",
    "\n",
    "coexpression_lookup = read_json_from(coexpression_lookup_path)\n",
    "cooccurence_lookup = read_json_from(cooccurence_lookup_path)\n",
    "experiments_lookup = read_json_from(experiments_lookup_path)\n",
    "fusion_lookup = read_json_from(fusion_lookup_path)\n",
    "homology_lookup = read_json_from(homology_lookup_path)\n",
    "cocomplex_lookup = read_json_from(cocomplex_lookup_path)\n",
    "database_lookup = read_json_from(database_lookup_path)\n",
    "\n",
    "lookup_list = [coexpression_lookup,cooccurence_lookup,experiments_lookup,fusion_lookup,homology_lookup,cocomplex_lookup,database_lookup]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN\n",
    "def get_top_k_nearest_neighbors(vector,k,candidates,dist_function):\n",
    "    k += 1\n",
    "    dist_to_all = np.array(list(map(lambda x: dist_function(vector,x),candidates)))\n",
    "    neighbor_indices = np.argpartition(dist_to_all, k)[0:k]\n",
    "    neighbor_indices = neighbor_indices[np.argsort(dist_to_all[neighbor_indices])]\n",
    "    neighbor_indices = neighbor_indices[1:]\n",
    "    top_k_neighbors_dist = dist_to_all[neighbor_indices]\n",
    "    return neighbor_indices,top_k_neighbors_dist\n",
    "\n",
    "# returns report json containing relations between two proteins\n",
    "def eval_relation(protein1,protein2):\n",
    "    report_json = {}\n",
    "    for lookup in lookup_list:\n",
    "        lookup_type = lookup['relation_type']\n",
    "        relation_score = float('NaN')\n",
    "        try:\n",
    "            relation_score = lookup[protein1][protein2]\n",
    "        except KeyError:\n",
    "            pass\n",
    "        report_json[lookup_type] = relation_score\n",
    "    return report_json\n",
    "\n",
    "# Only returns names of the top k nearest neighbors\n",
    "def protein_query_simple(protein,k,dist_function,name_vector,feature_matrix,lookup):\n",
    "    protein_idx = lookup[protein]\n",
    "    protein_vec = feature_matrix[protein_idx]\n",
    "    if dist_function.__name__ == 'euclidean_dist':\n",
    "        diff_vec = feature_matrix - protein_vec\n",
    "        norm_vec = np.linalg.norm(diff_vec, axis=1)\n",
    "        top_indices = take_top_k(norm_vec,k+1)[1:]\n",
    "        return name_vector[top_indices]\n",
    "    else:\n",
    "        neighbor_indices,_ = get_top_k_nearest_neighbors(protein_vec,k,feature_matrix,dist_function)\n",
    "        return name_vector[neighbor_indices] \n",
    "\n",
    "def get_closest_neighbors_in_embeddings(protein,k,embeddings,lookup,dist_func):\n",
    "    neighbor_lists = []\n",
    "    for embedding in embeddings:\n",
    "        protein_vec = embedding[lookup[protein]]\n",
    "        neighbor_indices,_ = get_top_k_nearest_neighbors(protein_vec,k,embedding,dist_func)\n",
    "        neighbor_lists.append(neighbor_indices)\n",
    "    return neighbor_lists\n",
    "\n",
    "def get_common_closest_neighbors_in_embeddings(protein,k,embeddings,lookup,dist_func):\n",
    "    neighbor_lists = get_closest_neighbors_in_embeddings(protein,k,embeddings,lookup,dist_func)\n",
    "    shared_proteins_indices = reduce(np.intersect1d, neighbor_lists)\n",
    "    name_list = list(map(lambda x: shared_proteins[x], shared_proteins_indices))\n",
    "    return name_list\n",
    "\n",
    "def calc_interaction_count(protein,candidates):\n",
    "    count = 0\n",
    "    for candidate in candidates:\n",
    "        relation_report = eval_relation(protein,candidate)\n",
    "        if relation_report['cocomplex'] > 0 or relation_report['experiments'] > 0 or relation_report['database'] > 0:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def overall_interaction_counts(proteins,interation_candidates):\n",
    "    assert len(proteins) == len(interation_candidates)\n",
    "    count_list = []\n",
    "    for i in range(len(proteins)):\n",
    "        short_list = []\n",
    "        # Number of interacting proteins\n",
    "        short_list.append(calc_interaction_count(proteins[i],interation_candidates[i]))\n",
    "        # Number of overlapping proteins\n",
    "        short_list.append(len(interation_candidates[i]))\n",
    "        count_list.append(short_list)\n",
    "    return count_list\n",
    "\n",
    "def calc_combined_counts(proteins,candidates_1,candidates_2):\n",
    "    assert len(proteins) == len(candidates_1) and len(candidates_1) == len(candidates_2)\n",
    "    count_list = []\n",
    "    for i in range(len(proteins)):\n",
    "        short_list = []\n",
    "        intersection = np.intersect1d(candidates_1[i],candidates_2[i])\n",
    "        jaccard = len(intersection) / (len(candidates_1[i]) + len(candidates_2[i]) - len(intersection))\n",
    "        # Number of interacting proteins\n",
    "        short_list.append(calc_interaction_count(proteins[i],intersection))\n",
    "        # Number of overlapping proteins\n",
    "        short_list.append(len(intersection))\n",
    "        # Jaccard Similarity\n",
    "        short_list.append(jaccard)\n",
    "        count_list.append(short_list)\n",
    "    return count_list\n",
    "\n",
    "def euclidean_dist(vec1,vec2):\n",
    "    return np.linalg.norm(vec1-vec2)\n",
    "\n",
    "def combined_count_statistics(combined_count):\n",
    "    combined_count = np.array(combined_count)\n",
    "    # ALL\n",
    "    combined_filtered_all = np.array(list(filter(lambda x: x[1] >= 1, combined_count)))\n",
    "    combined_filtered_all_precision = np.sum(combined_filtered_all[:,0]) / np.sum(combined_filtered_all[:,1])\n",
    "    # J >= 0.2\n",
    "    combined_filtered_J = np.array(list(filter(lambda x: x[2] >= 0.2, combined_count)))\n",
    "    combined_filtered_J_precision = 0\n",
    "    if (len(combined_filtered_J) > 0):\n",
    "        combined_filtered_J_precision = np.sum(combined_filtered_J[:,0]) / np.sum(combined_filtered_J[:,1])\n",
    "    # Known >= 1\n",
    "    combined_filtered_known = np.array(list(filter(lambda x: x[0] >= 1 and x[1] >= 2, combined_count)))\n",
    "    combined_filtered_known_precision = 0\n",
    "    if (len(combined_filtered_known) > 0):\n",
    "        combined_filtered_known_precision = np.sum(combined_filtered_known[:,0]) / np.sum(combined_filtered_known[:,1])\n",
    "    return combined_filtered_all_precision,combined_filtered_J_precision,combined_filtered_known_precision,np.sum(combined_filtered_all[:,1]),np.sum(combined_filtered_J[:,1]),np.sum(combined_filtered_known[:,1])\n",
    "\n",
    "def draw_bar(xs,ys,neighbor_k,data_name,y_label,title,ylim=None,colors=None):\n",
    "    x_pos = [i for i, _ in enumerate(xs)]\n",
    "    plt.bar(x_pos, ys,color=colors)\n",
    "    plt.xlabel(f\"{data_name}, k={neighbor_k}\")\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.xticks(x_pos, xs)\n",
    "    if ylim:\n",
    "        plt.ylim(ylim)\n",
    "    plt.show()\n",
    "    \n",
    "# Cut an embedding into chunks with size n\n",
    "def chunk_features(embedding,n):\n",
    "    columns_to_cut = [ i for i in range(n,embedding.shape[1],n)]\n",
    "    return np.hsplit(embedding,columns_to_cut)\n",
    "\n",
    "\n",
    "def calc_appearance_freq(neighbors):\n",
    "    unique, counts = np.unique(neighbors, return_counts=True)\n",
    "    return np.asarray((unique, counts)).T\n",
    "\n",
    "# Indices of the top k element in the given array\n",
    "def take_top_k(arr,k,desc=False):\n",
    "    if desc: arr = -arr\n",
    "    part = np.argpartition(arr,k)[:k]\n",
    "    correct_order = np.argsort(arr[part])\n",
    "    return part[correct_order]\n",
    "\n",
    "# Keep chunk_size small but neighbor size big\n",
    "def generate_link_candidates(protein,name_vector,embedding,lookup,candidate_size=5,neighbor_size=30,chunk_size=5,dist=euclidean_dist,return_all=False):\n",
    "    protein_vec = embedding[lookup[protein]]\n",
    "    diff_embeddeding = embedding - protein_vec\n",
    "    chunked_embeddings = chunk_features(diff_embeddeding,chunk_size)\n",
    "    candidates = np.zeros((len(chunked_embeddings),neighbor_size))\n",
    "    for idx,chunk in enumerate(chunked_embeddings):\n",
    "        norm_vec = np.linalg.norm(chunk, axis=1)\n",
    "        top_indices = take_top_k(norm_vec,neighbor_size+1)[1:]\n",
    "        candidates[idx] = top_indices\n",
    "    interaction_freq_indices = calc_appearance_freq(candidates)\n",
    "    top_interacting_indices = take_top_k(interaction_freq_indices[:,1],candidate_size,desc=True)\n",
    "    top_interacting = name_vector[interaction_freq_indices[top_interacting_indices][:,0].astype(int)]\n",
    "    return top_interacting\n",
    "    \n",
    "#proteomeHD_closest_neighbors = list(map(lambda x: protein_query_simple(x,k,euclidean_dist,shared_proteins,proteomeHD_shared_df_feature_matrix,shared_lookup),shared_proteins))\n",
    "# def generate_rank_distance_matrix(embedding):\n",
    "#     rows = embedding.shape[0]\n",
    "#     final_matrix = np.zeros((rows,rows))\n",
    "#     for i in range(rows):\n",
    "#         diff_vec = embedding - embedding[i]\n",
    "#         norm_vec = np.linalg.norm(diff_vec, axis=1)\n",
    "#         sort_vec = np.argsort(norm_vec)\n",
    "#         rank_vec = np.zeros(rows)\n",
    "#         for j in range(rows):\n",
    "#             rank_vec[sort_vec[j]] = j\n",
    "#         final_matrix[i] = rank_vec\n",
    "#     return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.852e+03 6.000e+00]\n",
      " [2.905e+03 5.000e+00]\n",
      " [1.989e+03 5.000e+00]\n",
      " ...\n",
      " [6.479e+03 1.000e+00]\n",
      " [6.480e+03 1.000e+00]\n",
      " [6.000e+00 1.000e+00]]\n",
      "[[5.852e+03 6.000e+00]\n",
      " [2.905e+03 5.000e+00]\n",
      " [1.989e+03 5.000e+00]\n",
      " [2.191e+03 5.000e+00]\n",
      " [1.881e+03 5.000e+00]]\n",
      "Wall time: 25 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Q7Z6Z7', 'P45974', 'P14868', 'P20073', 'P12081'], dtype=object)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time generate_link_candidates('A0AVT1',proteomeHD_simplified_protein_ids,proteomeHD_feature_matrix,major_simplified_idx_lookup,CANDIDATE_SIZE,NEIGHBOR_SIZE,CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANDIDATE_SIZE = 5\n",
    "NEIGHBOR_SIZE = 30\n",
    "CHUNK_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProteomeHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time proteomeHD_knn_candidates = np.array(list(map(lambda x: protein_query_simple(x,CANDIDATE_SIZE,euclidean_dist,proteomeHD_simplified_protein_ids,proteomeHD_feature_matrix,major_simplified_idx_lookup),proteomeHD_simplified_protein_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%time proteomeHD_chunked_candidates = np.array(list(map(lambda x: generate_link_candidates(x,proteomeHD_simplified_protein_ids,proteomeHD_feature_matrix,major_simplified_idx_lookup,CANDIDATE_SIZE,NEIGHBOR_SIZE,CHUNK_SIZE),proteomeHD_simplified_protein_ids))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.044134457037682845"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomeHD_knn_interaction_counts = np.array(overall_interaction_counts(proteomeHD_simplified_protein_ids,proteomeHD_knn_candidates))\n",
    "proteomeHD_knn_precision = np.sum(proteomeHD_knn_interaction_counts[:,0]) / np.sum(proteomeHD_knn_interaction_counts[:,1])\n",
    "proteomeHD_knn_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04126707352513804"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomeHD_chunked_interaction_counts = np.array(overall_interaction_counts(proteomeHD_simplified_protein_ids,proteomeHD_chunked_candidates))\n",
    "proteomeHD_chunked_precision = np.sum(proteomeHD_chunked_interaction_counts[:,0]) / np.sum(proteomeHD_chunked_interaction_counts[:,1])\n",
    "proteomeHD_chunked_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pQTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time pQTL_knn_candidates = np.array(list(map(lambda x: protein_query_simple(x,CANDIDATE_SIZE,euclidean_dist,pQTL_protein_ids,pQTL_protein_feature_matrix,pQTL_protein_idx_lookup),pQTL_protein_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13648523985239852"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pQTL_knn_interaction_counts = np.array(overall_interaction_counts(pQTL_protein_ids,pQTL_knn_candidates))\n",
    "pQTL_knn_precision = np.sum(pQTL_knn_interaction_counts[:,0]) / np.sum(pQTL_knn_interaction_counts[:,1])\n",
    "pQTL_knn_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.54 s\n"
     ]
    }
   ],
   "source": [
    "%time pQTL_chunked_candidates = np.array(list(map(lambda x: generate_link_candidates(x,pQTL_protein_ids,pQTL_protein_feature_matrix,pQTL_protein_idx_lookup,CANDIDATE_SIZE,NEIGHBOR_SIZE,CHUNK_SIZE),pQTL_protein_ids))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11748154981549816"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pQTL_chunked_interaction_counts = np.array(overall_interaction_counts(pQTL_protein_ids,pQTL_chunked_candidates))\n",
    "pQTL_chunked_precision = np.sum(pQTL_chunked_interaction_counts[:,0]) / np.sum(pQTL_chunked_interaction_counts[:,1])\n",
    "pQTL_chunked_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nikolai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%time nikolai_knn_candidates = np.array(list(map(lambda x: protein_query_simple(x,CANDIDATE_SIZE,euclidean_dist,nikolai_protein_ids,nikolai_protein_feature_matrix,nikolai_protein_idx_lookup),nikolai_protein_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004329004329004329"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikolai_knn_interaction_counts = np.array(overall_interaction_counts(nikolai_protein_ids,nikolai_knn_candidates))\n",
    "nikolai_knn_precision = np.sum(nikolai_knn_interaction_counts[:,0]) / np.sum(nikolai_knn_interaction_counts[:,1])\n",
    "nikolai_knn_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%time nikolai_chunked_candidates = np.array(list(map(lambda x: generate_link_candidates(x,nikolai_protein_ids,nikolai_protein_feature_matrix,nikolai_protein_idx_lookup,CANDIDATE_SIZE,NEIGHBOR_SIZE,CHUNK_SIZE),nikolai_protein_ids))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.015584415584415584"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nikolai_chunked_interaction_counts = np.array(overall_interaction_counts(nikolai_protein_ids,nikolai_chunked_candidates))\n",
    "nikolai_chunked_precision = np.sum(nikolai_chunked_interaction_counts[:,0]) / np.sum(nikolai_chunked_interaction_counts[:,1])\n",
    "nikolai_chunked_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-245-4b684acb21a3>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-245-4b684acb21a3>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    input = torch.randn(20, 1, ,1,50)\u001b[0m\n\u001b[1;37m                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "m = nn.Conv1d(16, 33, 3, stride=2)\n",
    "input = torch.randn(20, 16, 50)\n",
    "output = m(input)\n",
    "\n",
    "# class Conv1DNet(nn.module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super(Conv1DNet,self).__init__()\n",
    "#         self.conv1 = nn.Conv1D()\n",
    "    \n",
    "#     def forward(self,x):\n",
    "#         pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 24])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 16, 50])"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomeHD_corr_mat = np.corrcoef(proteomeHD_feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomeHD_corr_candidates = []\n",
    "for i in range(len(proteomeHD_corr_mat)):\n",
    "    top_candidates = take_top_k(proteomeHD_corr_mat[i],CANDIDATE_SIZE+1,desc=True)[1:]\n",
    "    proteomeHD_corr_candidates.append(proteomeHD_simplified_protein_ids[top_candidates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05756078659304466"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proteomeHD_corr_interaction_counts = np.array(overall_interaction_counts(proteomeHD_simplified_protein_ids,proteomeHD_corr_candidates))\n",
    "proteomeHD_corr_precision = np.sum(proteomeHD_corr_interaction_counts[:,0]) / np.sum(proteomeHD_corr_interaction_counts[:,1])\n",
    "proteomeHD_corr_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python37064bitdd6a2358527242ea897ba8dd6dc37158"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
